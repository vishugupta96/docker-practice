{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYoVrnewenmh"
   },
   "source": [
    "### Codebasics - Bag of N grams tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYoVrnewenmh"
   },
   "source": [
    "##### Let's first understand how to generate n-grams using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 5, 'hathodawala': 1, 'is': 2, 'looking': 4, 'for': 0, 'job': 3}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "v = CountVectorizer()\n",
    "v.fit([\"Thor Hathodawala is looking for a job\"])\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 9,\n",
       " 'hathodawala': 2,\n",
       " 'is': 4,\n",
       " 'looking': 7,\n",
       " 'for': 0,\n",
       " 'job': 6,\n",
       " 'thor hathodawala': 10,\n",
       " 'hathodawala is': 3,\n",
       " 'is looking': 5,\n",
       " 'looking for': 8,\n",
       " 'for job': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = CountVectorizer(ngram_range=(1,2))\n",
    "v.fit([\"Thor Hathodawala is looking for a job\"])\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 12,\n",
       " 'hathodawala': 2,\n",
       " 'is': 5,\n",
       " 'looking': 9,\n",
       " 'for': 0,\n",
       " 'job': 8,\n",
       " 'thor hathodawala': 13,\n",
       " 'hathodawala is': 3,\n",
       " 'is looking': 6,\n",
       " 'looking for': 10,\n",
       " 'for job': 1,\n",
       " 'thor hathodawala is': 14,\n",
       " 'hathodawala is looking': 4,\n",
       " 'is looking for': 7,\n",
       " 'looking for job': 11}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = CountVectorizer(ngram_range=(1,3))\n",
    "v.fit([\"Thor Hathodawala is looking for a job\"])\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not take a simple collection of text documents, preprocess them to remove stop words, lemmatize etc and then generate bag of 1 grams and 2 grams from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Thor ate pizza\",\n",
    "    \"Loki is tall\",\n",
    "    \"Loki is eating pizza\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# load english language model and create nlp object from it\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "def preprocess(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return \" \".join(filtered_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thor eat pizza'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"Thor ate pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loki eat pizza'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"Loki is eating pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thor eat pizza', 'Loki tall', 'Loki eat pizza']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_processed = [\n",
    "    preprocess(text) for text in corpus\n",
    "]\n",
    "corpus_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thor': 7,\n",
       " 'eat': 0,\n",
       " 'pizza': 5,\n",
       " 'thor eat': 8,\n",
       " 'eat pizza': 1,\n",
       " 'loki': 2,\n",
       " 'tall': 6,\n",
       " 'loki tall': 4,\n",
       " 'loki eat': 3}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = CountVectorizer(ngram_range=(1,2))\n",
    "v.fit(corpus_processed)\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate bag of n gram vector for few sample documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.transform([\"Thor eat pizza\"]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a document that has out of vocabulary (OOV) term and see how bag of ngram generates vector out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.transform([\"Hulk eat pizza\"]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"thor_hulk.jpg\" width=800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News Category Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay now that we know basics of BAG of n grams vectorizer ðŸ˜Ž It is the time to work on a real problem. Here we want to do a news category classification. We will use bag of n-grams and traing a machine learning model that can categorize any news into one of the following categories,\n",
    "\n",
    "1. BUSINESS\n",
    "1. SPORTS\n",
    "1. CRIME\n",
    "1. SCIENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "\n",
    "Dataset Credits: https://www.kaggle.com/code/hengzheng/news-category-classifier-val-acc-0-65\n",
    "\n",
    "- This data consists of two columns.\n",
    "        - Text\n",
    "        - Category\n",
    "- Text is a news article\n",
    "- Category can be one of these 4: 'BUSINESS', 'SPORTS', 'CRIME', 'SCIENCE', to keep things simple I trimmed additional categories from the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12695, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Watching SchrÃ¶dinger's Cat Die University of C...</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WATCH: Freaky Vortex Opens Up In Flooded Lake</td>\n",
       "      <td>SCIENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entrepreneurs Today Don't Need a Big Budget to...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>These Roads Could Recharge Your Electric Car A...</td>\n",
       "      <td>BUSINESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Civilian 'Guard' Fires Gun While 'Protecting' ...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category\n",
       "0  Watching SchrÃ¶dinger's Cat Die University of C...   SCIENCE\n",
       "1     WATCH: Freaky Vortex Opens Up In Flooded Lake    SCIENCE\n",
       "2  Entrepreneurs Today Don't Need a Big Budget to...  BUSINESS\n",
       "3  These Roads Could Recharge Your Electric Car A...  BUSINESS\n",
       "4  Civilian 'Guard' Fires Gun While 'Protecting' ...     CRIME"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('news_dataset.json')\n",
    "print(df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BUSINESS    4254\n",
       "SPORTS      4167\n",
       "CRIME       2893\n",
       "SCIENCE     1381\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Handle class imbalance**\n",
    "\n",
    "As you can see above, SCIENCE category has almost 1/3rd data samples compared to BUSINESS and SPORTS categories. I initially trained a model without handling the imbalanced I saw a lower f1-score for SCIENCE category. Hence we need to address this imbalanced. \n",
    "\n",
    "There are various ways of handling class imbalance which I have discussed in this video: https://www.youtube.com/watch?v=JnlM4yLFNuo\n",
    "\n",
    "\n",
    "Out of those techniques, I will use **undersampling** technique here. \n",
    "\n",
    "In undersampling, we take a minor class and sample those many samples from other classes, this means we are not utilizing all the data samples for training and in ML world - Not using all the data for training is considered a SIN! ðŸ˜µ In real life, you are advised to use a technique such as SMOTE so that you can utilize all of your dataset for the training but since this tutorial is more about bag of n-grams then class imbalance itself, I'd go with a simple technique of undersampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples = 1381 # we have these many SCIENCE articles and SCIENCE is our minority class\n",
    "\n",
    "\n",
    "df_business = df[df.category==\"BUSINESS\"].sample(min_samples, random_state=2022)\n",
    "df_sports = df[df.category==\"SPORTS\"].sample(min_samples, random_state=2022)\n",
    "df_crime = df[df.category==\"CRIME\"].sample(min_samples, random_state=2022)\n",
    "df_science = df[df.category==\"SCIENCE\"].sample(min_samples, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIME       1381\n",
       "BUSINESS    1381\n",
       "SPORTS      1381\n",
       "SCIENCE     1381\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = pd.concat([df_business,df_sports,df_crime,df_science],axis=0)\n",
    "df_balanced.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert text category to a number**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = {'BUSINESS': 0, 'SPORTS': 1, 'CRIME': 2, 'SCIENCE': 3}\n",
    "\n",
    "df_balanced['category_num'] = df_balanced['category'].map({\n",
    "    'BUSINESS': 0,\n",
    "    'SPORTS': 1, \n",
    "    'CRIME': 2, \n",
    "    'SCIENCE': 3\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11967</th>\n",
       "      <td>GCC Business Leaders Remain Confident in the F...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>From the Other Side; an Honest Review from Emp...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>Mike McDerment, CEO of FreshBooks, Talks About...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>How to Market Your Business While Traveling th...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>How to Leverage Intuition in Decision-making I...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  category  \\\n",
       "11967  GCC Business Leaders Remain Confident in the F...  BUSINESS   \n",
       "2912   From the Other Side; an Honest Review from Emp...  BUSINESS   \n",
       "3408   Mike McDerment, CEO of FreshBooks, Talks About...  BUSINESS   \n",
       "502    How to Market Your Business While Traveling th...  BUSINESS   \n",
       "5279   How to Leverage Intuition in Decision-making I...  BUSINESS   \n",
       "\n",
       "       category_num  \n",
       "11967             0  \n",
       "2912              0  \n",
       "3408              0  \n",
       "502               0  \n",
       "5279              0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a model with original text (no pre processing)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_balanced.text, \n",
    "    df_balanced.category_num, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022,\n",
    "    stratify=df_balanced.category_num\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4419,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7589     Ovulating Women Prefer Images of Penetration O...\n",
       "10442    Scientists Discover Spooky Influence On Baby N...\n",
       "8792     Olympic Race Walker Steps Up To Propose To His...\n",
       "1733     Beloved Bipedal Bear Named Pedals Believed Kil...\n",
       "2526     Elizabeth Smart Gave Birth To Baby Girl, Fathe...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1105\n",
       "2    1105\n",
       "0    1105\n",
       "1    1104\n",
       "Name: category_num, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    277\n",
       "3    276\n",
       "2    276\n",
       "0    276\n",
       "Name: category_num, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attempt 1 : Use 1-gram which is nothing but a Bag Of Words (BOW) model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.87      0.81       276\n",
      "           1       0.93      0.80      0.86       277\n",
      "           2       0.83      0.90      0.86       276\n",
      "           3       0.90      0.80      0.85       276\n",
      "\n",
      "    accuracy                           0.84      1105\n",
      "   macro avg       0.85      0.84      0.84      1105\n",
      "weighted avg       0.85      0.84      0.84      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_bow', CountVectorizer(ngram_range = (1, 1))),        #using the ngram_range parameter \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3716     african Nation slap Exxon Fine nearly 7 time g...\n",
       "608               Cringe Worthy Stories hard woman Science\n",
       "11172    LISTEN Accidental Discovery prove Big Bang Theory\n",
       "1346     Build Loyalty cost $ 00.00 remember customer h...\n",
       "1356     Man kill Michigan Police target cop understand...\n",
       "Name: preprocessed_txt, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BUSINESS: 0\n",
    "- SPORTS: 1\n",
    "- CRIME: 2\n",
    "- SCIENCE: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 3, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3716     0\n",
       "608      3\n",
       "11172    3\n",
       "1346     0\n",
       "1356     2\n",
       "Name: category_num, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attempt 2 : Use 1-gram and bigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78       276\n",
      "           1       0.95      0.74      0.83       277\n",
      "           2       0.82      0.88      0.85       276\n",
      "           3       0.92      0.78      0.84       276\n",
      "\n",
      "    accuracy                           0.82      1105\n",
      "   macro avg       0.85      0.82      0.83      1105\n",
      "weighted avg       0.85      0.82      0.83      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_1_2_gram', CountVectorizer(ngram_range = (1, 2))),        #using the ngram_range parameter \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attempt 3 : Use 1-gram to trigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.91      0.77       276\n",
      "           1       0.96      0.73      0.83       277\n",
      "           2       0.83      0.87      0.85       276\n",
      "           3       0.93      0.76      0.83       276\n",
      "\n",
      "    accuracy                           0.82      1105\n",
      "   macro avg       0.84      0.82      0.82      1105\n",
      "weighted avg       0.84      0.82      0.82      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_1_3_grams', CountVectorizer(ngram_range = (1, 3))),        #using the ngram_range parameter \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use text pre-processing to remove stop words, punctuations and apply lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may wonder, we have not done any text-processing yet to remove stop words, punctuations, apply lemmatization etc. Well we wanted to train the model without any preprocessing first and check the performance. Now we will re-do same thing but with preprocessing of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced['preprocessed_txt'] = df_balanced['text'].apply(preprocess) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>category_num</th>\n",
       "      <th>preprocessed_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11967</th>\n",
       "      <td>GCC Business Leaders Remain Confident in the F...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>gcc Business leader remain Confident face Regi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>From the Other Side; an Honest Review from Emp...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>Honest Review employee wake morning love impor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>Mike McDerment, CEO of FreshBooks, Talks About...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>Mike McDerment ceo FreshBooks talk give build ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>How to Market Your Business While Traveling th...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>market business travel World recently amazing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>How to Leverage Intuition in Decision-making I...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>0</td>\n",
       "      <td>Leverage intuition decision making feel safe r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  category  \\\n",
       "11967  GCC Business Leaders Remain Confident in the F...  BUSINESS   \n",
       "2912   From the Other Side; an Honest Review from Emp...  BUSINESS   \n",
       "3408   Mike McDerment, CEO of FreshBooks, Talks About...  BUSINESS   \n",
       "502    How to Market Your Business While Traveling th...  BUSINESS   \n",
       "5279   How to Leverage Intuition in Decision-making I...  BUSINESS   \n",
       "\n",
       "       category_num                                   preprocessed_txt  \n",
       "11967             0  gcc Business leader remain Confident face Regi...  \n",
       "2912              0  Honest Review employee wake morning love impor...  \n",
       "3408              0  Mike McDerment ceo FreshBooks talk give build ...  \n",
       "502               0  market business travel World recently amazing ...  \n",
       "5279              0  Leverage intuition decision making feel safe r...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a model with pre processed text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_balanced.preprocessed_txt, \n",
    "    df_balanced.category_num, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022,\n",
    "    stratify=df_balanced.category_num\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4419,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7589     ovulate woman prefer Images Penetration image ...\n",
       "10442     scientist Discover Spooky Influence Baby Choices\n",
       "8792     Olympic Race Walker step Propose Boyfriend Rio...\n",
       "1733     Beloved Bipedal Bear name Pedals believe kill ...\n",
       "2526       Elizabeth Smart give Birth Baby Girl Father say\n",
       "Name: preprocessed_txt, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1105\n",
       "2    1105\n",
       "0    1105\n",
       "1    1104\n",
       "Name: category_num, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    277\n",
       "3    276\n",
       "2    276\n",
       "0    276\n",
       "Name: category_num, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       276\n",
      "           1       0.92      0.83      0.87       277\n",
      "           2       0.83      0.92      0.87       276\n",
      "           3       0.91      0.81      0.86       276\n",
      "\n",
      "    accuracy                           0.86      1105\n",
      "   macro avg       0.87      0.86      0.86      1105\n",
      "weighted avg       0.87      0.86      0.86      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_bow', CountVectorizer(ngram_range = (1, 2))),        #using the ngram_range parameter \n",
    "    ('Multi NB', MultinomialNB())\n",
    "])\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you compare above classification report for (1,2) gram with the one from unprocessed text, you will find some improvement in the model that uses preprocessed cleaned up text. Hence we can conclude that for this particular problem using preprocessing (removing stop words, lemmatization) is improving the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[242,   9,  15,  10],\n",
       "       [ 10, 230,  29,   8],\n",
       "       [ 15,   1, 255,   5],\n",
       "       [ 34,  10,   8, 224]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Truth')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BOW_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
